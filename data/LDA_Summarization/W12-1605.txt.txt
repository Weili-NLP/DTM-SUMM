Unsupervised Topic Modeling Approaches to Decision Summarization in Spoken Meetings We present a token - level decision summarization framework that utilizes the latent topic structures of utterances to identify " summary - worthy " words .
Concretely , a series of unsupervised topic models is explored and experimental results show that fine - grained topic models , which discover topics at the utterance - level rather than the document - level , can better identify the gist of the decision - making process .
Moreover , our proposed token - level summarization approach , which is able to remove redundancies within utterances , outperforms existing utterance ranking based summarization methods .
Finally , context information is also investigated to add additional relevant information to the summary .
1 Introduction Meetings are an important way for information sharing and collaboration , where people can discuss problems and make concrete decisions .
Not surprisingly , there is an increasing interest in developing methods for extractive summarization for meetings and conversations ( Zechner , 2002 ; Maskey and Hirschberg , 2005 ; Galley , 2006 ; Lin and Chen , describe the specific need for focused summaries of meetings , i . e ., summaries of a particular aspect of a meeting rather than of the meeting as a whole .
For example , the decisions made , the action items that emerged and the problems arised are all important outcomes of meetings .
In particular , decision summaries would allow participants to review decisions from previous meetings and understand the related topics quickly , which facilitates preparation for the upcoming meetings .
Figure 1 : A clip of a meeting from the AMI meeting corpus ( Carletta et al ., 2005 ).
A , B , C and D refer to distinct speakers ; the numbers in parentheses indicate the associated meeting decision : decision 1 , 2 , 3 or 4 .
Also shown is the gold - standard ( manual ) abstract ( summary ) for each decision .
Meeting conversation is intrinsically different from well - written text , as meetings may not be well organized and most utterances have low density of salient content .
Therefore , multiple problems need to be addressed for speech summarization .
Consider the sample dialogue snippet in Figure 1 from the AMI meeting corpus ( Carletta et al ., 2005 ).
Only decision - related dialogue acts ( DRDAs ) — utterances at least one decision made in the meeting — are listed and ordered by time .
Each DRDA is labeled numerically according to the decision it supports ; so the second and third utterances ( in bold ) support Decision 2 , as do the fifth utterance in the snippet .
Manually constructed decision abstracts for each decision are shown at the bottom of the figure .
Besides the prevalent dialogue phenomena ( such as " Uh I ' m kinda liking " in Figure 1 ), disfluencies and off - topic expressions , we notice that single utterance is usually not informative enough to form a decision .
For instance , no single DRDA associated with Decision 4 corresponds all that well with its decision abstract : " pushbuttons ", " menu button " and " Pre - set channels " are mentioned in separate DAs .
As a result , extractive summarization methods that select individual utterance to form the summary will perform poorly .
Furthermore , it is difficult to identify the core topic when multiple topics are discussed in one utterance .
For example , all of the bold DRDAs supporting DECISION 2 contain the word " latex ".
However , the last DA in bold also mentions " bigger impact " and " the scroll wheel ", which are not specifically relevant for DECISION 2 .
Though this problem can be approached by training a classifier to identify the relevant phrases and ignore the irrelevant ones or dialogue phenomena , it needs expensive human annotation and is limited to the specific domain .
Note also that for Decision 4 , the " power button " is not specified in any of the listed DRDAs supporting it .
By looking at the transcript , we find " power button " mentioned in one of the preceding , but not decision - related DAs .
Consequently another challenge would be to add complementary knowledge when the DRDAs cannot provide complete information .
Therefore , we need a summarization approach that is tolerant of dialogue phenomena , can determine the key semantic content and is easily transferable between domains .
Recently , topic modeling approaches have been investigated and achieved state - of - the - art results in multi - document summarization ( Haghighi and Vanderwende , 2009 ; Celikyilmaz and Hakkani - Tur , 2010 ).
Thus , topic models appear to be a better ref for document similarity w . r . t .
semantic concepts than simple literal word matching .
However , very little work has investigated its role in spoken document summarization ( Chen and Chen , 2008 ; Hazen , 2011 ), and much less conducted comparisons among topic modeling approaches for focused summarization in meetings .
These DRDAs are annotated in the AMI corpus and usually contain the decision content .
They are similar , but not completely equivalent , to the decision dialogue acts ( DDAs ) of Bui et al .
In contrast to previous work , we study the un - supervised token - level decision summarization in meetings by identifying a concise set of key words or phrases , which can either be output as a compact summary or be a starting point to generate abstractive summaries .
This paper addresses problems mentioned above and make contributions as follows : • As a step towards creating the abstractive summaries that people prefer when dealing with spoken language ( Murray et al ., 2010b ), we propose a token - level rather than sentence - level framework for identifying components of the summary .
Experimental results show that , compared to the sentence ranking based summarization algorithms , our token - level summarization framework can better identify the summary - worthy words and remove the redundancies .
• Rather than employing supervised learning methods that rely on costly manual annotation , we explore and evaluate topic modeling approaches of different granularities for the unsupervised decision summarization at both the token - level and dialogue act - level .
We investigate three topic models — Local LDA ( LocalLDA ) ( Brody and El - and McDonald , 2008 ) and Segmented Topic Model ( STM ) ( Du et al ., 2010 ) — which can utilize the latent topic structure on utterance level instead of document level .
Under our proposed token - level summarization framework , three finegrained models outperform the basic LDA model and two extractive baselines that select the longest and the most representative utterance for each decision , respectively .
( ROUGE - SU4 F score of 14 . 82 % for STM vs . 13 . 58 % and 13 . 46 % for the baselines , given the perfect clusterings of DR - • In line with prior research that explore the role of context for utterance - based extractive summariza - tion ( Murray and Renals , 2007 ), we investigate the role of context in our token - level summarization framework .
For the given clusters of DRDAs , We study two types of context information — the DAs preceding and succeeding a DRDA and DAs of high TF - IDF similarity with a DRDA .
We also investigate two ways to select relevant words from the context DA .
Experimental results show that two types of context have comparable effect , but selecting words from the dominant topic of the center DRDA performs better than from the dominant topic of the context DA .
Moreover , by leveraging context , the recall exceeds the provided up - perbound ' s recall ( ROUGE - 1 recall : 48 . 10 % vs . 45 . 05 % for upperbound by using DRDA only ) although the F scores decrease after adding context information .
Finally , we show that when the true DRDA clusterings are not available , adding context can improve both the recall and F score .
2 Related Work Speech and dialogue summarization has become important in recent years as the number of multimedia resources containing speech has grown .
A primary goal for most speech summarization systems is to account for the special characteristics of dialogue .
Early work in this area investigated supervised learning methods , including maximum entropy , conditional random fields ( CRFs ), and support vector machines ( SVMs ) ( Buist et al ., 2004 ; Galley , 2006 ; Xie et al ., 2008 ).
For unsupervised methods , maximal marginal relevance ( MMR ) is investigated in ( Zechner , 2002 ) and ( Xie and Liu , 2010 ) .
Gillick et al .
( 2009 ) introduce a concept - based global optimization framework by using integer linear programming ( ILP ).
only in very recent works has decision summarization been addressed in ( Fernandez et al ., 2011 ) .
( Fernandez et al ., 2008 ) and ( Bui et al ., 2009 ) utilize semantic parser to identify candidate phrases for decision summaries and employ SVM to rank those phrases .
They also train HMM and SVM directly on a set of decision - related dialogue acts on token level and use the classifiers to identify summary - worthy words .
Wang and Cardie ( 2011 ) provide an exploration on supervised and unsuper - vised learning for decision summarization on both utterance - and token - level .
our work also arises out of applying topic models to text summarization ( Bhandari et al ., 2008 ; Haghighi and Vanderwende , 2009 ; Celikyilmaz and Hakkani - Tur , 2010 ; Celikyilmaz and Hakkani - Tur , 2010 ).
Mostly , the sentences are ranked according to importance based on latent topic structures , and top ones are selected as the summary .
There are some works for applying document - level topic models to speech summarization ( Kong and shan Leek , 2006 ; Chen and Chen , 2008 ; Hazen , 2011 ).
Different from their work , we further investigate the topic models of fine granularity on sentence level and leverage context information for decision summarization task .
Most existing approaches for speech summarization result in a selection of utterances from the dialogue , which cannot remove the redundancy within utterances .
To eliminate the superfluous words , our work is also inspired by keyphrase extraction of meetings ( Liu et al ., 2009 ; Liu et al ., 2011 ) and keyphrase based summarization ( Riedhammer et al ., 2010 ).
However , a small set of keyphrases are not enough to concretely display the content .
Instead of only picking up keyphrases , our work identifies all of the summary - worthy words and phrases , and removes redundancies within utterances .
3 Summarization Frameworks In this section , we first present our proposed token - level decision summarization framework — Dom - Sum — which utilizes latent topic structure in utterances to extract words from Dominant Topic ( see details in Section 3 . 1 ) to form Summaries .
In Section 3 . 2 , we describe four existing sentence scoring metrics denoted as OneTopic , MultiTopic , TMM - Sum and KLSum which are also based on latent topic distributions .
We adopt them to the utterance - level summarization for comparison in Section 6 .
3 . 1 Token - level Summarization Framework Domsum takes as input the clusters of DRDAs ( with or without additional context DAs ), the topic distribution for each DA and the word distribution for each topic .
The output is a set of topic - coherent summary - worthy words which can be used directly as the summary or to further generate abstractive summary .
We introduce DomSum in two steps according to its input : taking clusters of DRDAs as the input and with additional context information .
DRDAs Only .
Given clusters of DRDAs , we use Algorithm 1 to produce the token - level summary for each cluster .
Generally , Algorithm 1 chooses the topic with the highest probability as the dominant topic given the dialogue act ( DA ).
Then it collects the words with a high joint probability with the dominant topic from that DA .
Input : Cluster C = [ DAi ], P ( Tj \ DAi ), P ( wk \ Tj ) Output : Summary Summarys $ ( empty set ) foreach DAi in C do DomTopics maxTj P ( Tj \ DAi ) (*) Candidates $ foreach word in DAi do SampleTopics maxTj P ( wk \ Tj ) P ( Tj \ DAi ) if DomTopic == SampleTopic then I Candidate s Union ( Candidate , ) end Summary s Union ( Summary , Candidate ) Algorithm 1 : DomSum — The token - level summarization framework .
DomSum takes as input the clusters of DRDAs and related probability distributions .
Leveraging Context .
For each DRDA ( denoted as " center DA "), we study two types of context information ( denoted as " context DAs ").
One is adjacent DAs , i . e ., immediately preceding and succeeding DAs , the other is the DAs having top TF - IDF similarities with the center DA .
Context DAs are added into the cluster the corresponding center DA in .
We also study two criteria of word selection from the context DAs .
For each context DA , we can take the words appearing in the dominant topic of either this context DA or its center DRDA .
We will show in Section 6 . 1 that the latter performs better as it produces more topic - coherent summaries .
Algorithm 1 can be easily modified to leverage context DAs by updating the input clusters and assigning the proper dominant topic for each DA accordingly — this changes the step (*) in Algorithm 1 .
3 . 2 Utterance - level Summarization Metrics We also adopt four sentence scoring metrics based on the latent topic structure for extractive summarization .
Though they are developed on different topic models , given the desired topic distributions as input , they can rank the utterances according to their importance and provide utterance - level summaries for comparison .
OneTopic and MultiTopic .
In ( Bhandari et al ., 2008 ), several sentence scoring functions are introduced based on Probabilistic Latent Semantic Indexing .
We adopt two metrics , which are OneTopic and MultiTopic .
For OneTopic , topic T with highest probability P ( T ) is picked as the central topic per cluster C . The score for DA in C is : MultiTopic modifies OneTopic by taking all of the topics into consideration .
Given a cluster C , DA in C is scored as : DA ' eC , wEDA TMMSum .
Chen and Chen ( 2008 ) propose a Topical Mixture Model ( TMM ) for speech summarization , where each dialogue act is modeled as a TMM for generating the document .
TMM is shown to provide better utterance - level extractive summaries for spoken documents than other conventional unsu - pervised approaches , such as Vector Space Model ( VSM ) ( Gong and Liu , 2001 ), Latent Semantic Analysis ( LSA ) ( Gong and Liu , 2001 ) and Maximum Marginal Relevance ( MMR ) ( Murray et al ., 2005 ).
The importance of a sentence S can be measured by its generative probability P ( D \! S ), where D is the document S belongs to .
In our experiments , one decision is made per cluster of DAs .
So we adopt their scoring metric to compute the generative probability of the cluster C for each DA : KLSum .
Kullback - Lieber ( KL ) divergence is explored for summarization in ( Haghighi and Vander - wende , 2009 ) and ( Lin et al ., 2010 ), where it is used to measure the distance of distributions between the document and the summary .
For a cluster C of DAs , given a length limit 9 , a set of DAs S is selected as : 4 Topic Models In this section , we briefly describe the three finegrained topic models employed to compute the latent topic distributions on utterance level in the meetings .
According to the input of Algorithm 1 , we are interested in estimating the topic distribution for each DA P ( T \ DA ) and the word distribution for each topic P ( w \ T ).
For MG - LDA , P ( T \ DA ) is computed as the expectation of local topic distributions with respect to the window distribution .
4 . 1 Local LDA Local LDA ( LocalLDA ) ( Brody and Elhadad , 2010 ) uses almost the same probabilistic generative model as Latent Dirichlet Allocation ( LDA ) ( Blei et al ., 2003 ), except that it treats each sentence as a separate document .
Each DA d is generated as follows : 1 .
For each topic k : ( a ) Choose word distribution : 4 > k ~ Dir ( ß ) 2 .
For each DA d : ( a ) Choose topic distribution : 9d ~ Dir ( a ) ( b ) For each word w in DA d : 4 . 2 Multi - grain LDA Multi - grain LDA ( MG - LDA ) ( Titov and McDonald , 2008 ) can model both the meeting specific topics ( e . g .
the design of a remote control ) and various concrete aspects ( e . g .
the cost or the functionality ).
The generative process is : 1 .
Choose a global topic distribution : 9 ^ ~ Dir ( a gl ) 2 .
For each sliding window v of size T : ( b ) Choose granularity mixture : nm , v ~ Beta ( amix ) 3 .
For each DA d : ( a ) choose window distribution : ^ m > d ~ Dir ( j ) 4 .
For each word w in DA d of meeting m : ( a ) Choose sliding window : vm > w ~ ^ m > d ( b ) Choose granularity : rm > w ~ nm , Vm w ( e ) Choose word w from the word distribution : </> Zm ' m 4 . 3 Segmented Topic Model The last model we utilize is Segmented Topic Model ( STM ) ( Du et al ., 2010 ), which jointly models document - and sentence - level latent topics using a two - parameter Poisson Dirichlet Process ( PDP ).
Given parameters a , 7 , $ and PDP parameters a , b , the generative process is : 1 .
Choose distribution of topics : 9 m ~ Dir ( a ) 2 .
For each dialogue act d : For the generative process of LDA , the DAs in the same meeting make up the document , so " each DA " is changed to " each meeting " in LocalLDA ' s generative process .
( a ) Choose distribution of topics : 9d ~ PDP ( 9 3 .
For each word w in dialogue act d : 5 Experimental Setup The Corpus .
We evaluate our approach on the AMI meeting corpus ( Carletta et al ., 2005 ) that consists of 140 multi - party meetings .
The 129 scenario - driven meetings involve four participants playing different roles on a design team .
A short ( usually one - sentence ) abstract is manually constructed to summarize each decision discussed in the meeting and used as gold - standard summaries in our experiments .
System Inputs .
Our summarization system requires as input a partitioning of the DRDAs according to the decision ( s ) that each supports ( i . e ., one cluster of DRDAs per decision ).
As mentioned earlier , we assume for all experiments that the DRDAs for each meeting have been identified .
For evaluation we consider two system input settings .
In the True Clusterings setting , we use the AMI annotations to create perfect partitionings of the DRDAs as the input ; in the System Clusterings setting , we employ a hierarchical agglomerative clustering algorithm used for this task in previous work ( Wang and Cardie , 2011 ).
The Wang and Cardie ( 2011 ) clustering method groups DRDAs according to their LDA topic distribution similarity .
As better approaches for DRDA clustering become available , they could be employed instead .
Evaluation Metric .
To evaluate the performance of various summarization approaches , we use the widely accepted ROUGE ( Lin and Hovy , 2003 ) metrics .
We use the stemming option of the ROUGE software at http :// berouge . com / and remove stopwords from both the system and gold - standard summaries , same as Riedhammer et al .
Inference and Hyperparameters We use the implementation from ( Lu et al ., 2011 ) for the three topic models in Section 4 .
The collapsed Gibbs Sampling approach ( Griffiths and Steyvers , 2004 ) is exploited for inference .
Hyperparameters are chosen according to ( Brody and Elhadad , 2010 ), ( Titov and McDonald , 2008 ) and ( Du et al ., 2010 ).
In LDA and LocalLDA , a and ß are both set to 0 . 1 .
For MG - LDA , agl , aloc and amix are set to 0 . 1 ; 7 is 0 . 1 and the window size T is 3 .
And the number of local topic is set as the same number of global topic as a , a and b are set to 0 . 5 , 0 . 1 and 1 , respectively .
5 . 1 Baselines and Comparisons We compare our token - level summarization framework based on the fine - grained topic models to ( 1 ) two unsupervised baselines , ( 2 ) token - level summarization by LDA , ( 3 ) utterance - level summarization by Topical Mixture Model ( TMM ) ( Chen and Chen , 2008 ), ( 4 ) utterance - level summarization based on the fine - grained topic models using existing metrics ( Section 3 . 2 ), ( 5 ) two supervised methods , and ( 6 ) an upperbound derived from the AMI gold standard decision abstracts .
( 1 ) and ( 6 ) are described below , others will be discussed in Section 6 .
The Longest DA Baseline .
As in ( Riedhammer et al ., 2010 ) and ( Wang and Cardie , 2011 ), this baseline simply selects the longest DRDA in each cluster as the summary .
Thus , it performs utterance - level decision summarization .
This baseline and the next allow us to determine summary quality when summaries are restricted to a single utterance .
The Prototype DA Baseline .
Following Wang and Cardie ( 2011 ), the second baseline selects the decision cluster prototype ( i . e ., the DRDA with the largest TF - IDF similarity with the cluster centroid ) as the summary .
Upperbound .
We also compute an upperbound that reflects the gap between the best possible extractive summaries and the human - written abstracts according to the ROUGE score : for each cluster of DRDAs , we select the words that also appear in the associated decision abstract .
6 Results and Discussion 6 . 1 True Clusterings How do fine - grained topic models compare to basic topic models or baselines ?
Figure 2 demonstrates that by using the DomSum token - level summarization framework , the three fine - grained topic models uniformly outperform the two non - trivial baselines and TMM ( Chen and Chen , 2008 ) ( reim - plemented by us ) that generates utterance - level summaries .
Moreover , the fine - grained models also beat basic LDA under the same DomSum token - level summarization framework .
This shows the fine - Figure 2 : With true clusterings of DRDAs as the input , we use DomSum to compare the performance of LocalLDA , MGLDA and STM against two baselines , LDA and TMM . "
# topic " indicates the number of topics for the model .
For MGLDA , "# topic " is the number of local topics .
Figure 3 : With true clusterings of DRDAs as the input , Dom - Sum is compared with four DA - level summarization metrics using topic distributions from STM .
Results from LocalLDA and MGLDA are similar so they are not displayed .
grained topic models that discover topic structures on utterance - level better identify gist information .
Can the proposed token - level summarization framework better identify important words and remove redundancies than utterance selection methods ?
Figure 3 demonstrates the comparison results for our DomSum token - level summarization framework with four existing utterance scoring metrics discussed in Section 3 . 2 , namely OneTopic , MultiTopic , TMMSum and KLSum .
The utterance with highest score is extracted to form the summary .
LocalLDA and STM are utilized to compute the input distributions , i . e ., P ( T \ DA ) and P ( w \ T ).
From Figure 3 , DomSum yields the best F scores which Leveraging Context by STM Figure 4 : Under DomSum framework , two types of context information are added : Adjacent DA (" Adj ") and DAs with high TFIDF similarities (" TFIDF ").
For each context DA , selecting words from the dominant topic of center DA (" One ") or the current context DA (" Multi ") are investigated .
Summarization by Different Metrics ( adding Context ) Figure 5 : By using adjacent DAs as context , DomSum is compared with two DA - level summarization metrics : OneTopic and MultiTopic .
For DomSum , the words of context DA from dominant topic of the center DA (" One ") is selected ; For OneTopic and MultiTopic , three top ranked DAs are selected .
shows that the token - level summarization approach is more effective than utterance - level methods .
Which way is better for leveraging context information ?
We explore two types of context information .
For adjacent content ( Adj in Figure 4 ), 5 DAs immediately preceding and 5 DAs succeeding the center DRDA are selected .
For TF - IDF context ( TFIDF in Figure 4 ), 10 DAs of highest TF - IDF similarity with the center DRDA are taken .
We also explore two ways to extract summary - worthy words from the context DA — selecting words from the dominant topic of either the center DA ( denoted as " One " in parentheses in Figure 4 ) or the current context DA ( denoted as " multi " in parentheses in Fig - Table 1 : ROUGE - 1 ( R - 1 ), ROUGE - 2 ( R - 2 ) and ROUGE - SU4 ( R - SU4 ) scores for our proposed token - level summarization approaches along with two baselines , supervised methods and the Upperbound ( only using DRDAs ).
— all use True Clusterings ure 4 ).
Figure 4 indicates that the two types of context information do not have significant difference , while selecting the words from the dominant topic of the center DA results in better ROUGE - SU4 F scores .
Notice that compared with Figure 3 , the results in Figure 4 have lower F scores when using the true clusterings of DRDAs .
This is because context DAs bring in relevant words as well as noisy information .
We will show in Section 6 . 2 that when true clusterings are not available , the context information can boost both recall and F score .
How do the token - level summarization framework compared to utterance selection methods for leveraging context ?
We also compare the ability of leveraging context of DomSum to utterance scoring metrics , i . e ., OneTopic and MultiTopic .
5 DAs preceding and 5 DAs succeeding the center DA are added as context information .
For context DA under DomSum , we select words from the dominant topic of the center DA ( denoted as " One " in parentheses in Figure 5 ).
For OneTopic and Mul - tiTopic , the top 3 DAs are extracted as the summary .
Figure 5 demonstrates the combination of Lo - calLDA and STM with each of the metrics .
Dom - Sum , as a token - level summarization metrics , dominates other two metrics in leveraging context .
System Clusterings Table 2 : ROUGE - 1 ( R - 1 ), ROUGE - 2 ( R - 2 ) and ROUGE - SU4 ( R - SU4 ) scores for our proposed token - level summarization approaches , compared with two baselines and supervised methods .
— all use System Clusterings How do our approach perform when compared with supervised learning approaches ?
For a better comparison , we also provide summarization results by using supervised systems along with an upperbound .
We use Support Vector Machines ( Joachims , 1998 ) with RBF kernel and order - 1 Conditional Random Fields ( Lafferty et al ., 2001 ) — trained with the same features as ( Wang and Cardie , 2011 ) to identify the summary - worthy tokens to include in the abstract .
A three - fold cross validation is conducted for both methods .
ROUGE1 , ROUGE - 2 and ROUGE - SU4 scores are listed in Table 1 .
From Table 1 , our token - level summarization approaches based on LocalLDA and STM are shown to outperform the baselines and even the CRF .
Meanwhile , by adding context information , both LocalLDA and STM can get better ROUGE - 1 recall than the supervised methods , even higher than the provided upperbound which is computed by only using DRDAs .
This shows the DomSum framework can leverage context to compensate the summaries .
6 . 2 System Clusterings Results using the System Clusterings ( Table 2 ) present similar findings , though all of the system and baseline scores are lower .
By adding context information , the token - level summarization approaches based on fine - grained topic models compare favor - DRDA ( 1 ): I think if we can if we can include them at not too much extra cost , then I ' d put them in , DRDA ( 2 ): Uh um we we ' re definitely going in for voice recognition as well as LCDs , mm .
DRDA ( 3 ): So we ' ve basically worked out that we ' re going with a simple battery , context DA ( 1 ): So it ' s advanced integrated circuits ?
context DA ( 2 ): the advanced chip context DA ( 3 ): and a curved on one side case which is folded in on itself , um made out of rubber Decision Abstract : It will have voice recognition , use a simple battery , and contain an advanced chip .
Longest DA & Prototype DA : Uh um we we ' re definitely going in for voice recognition as well as LCDs , mm .
TMM : I think if we can if we can include them at not too much extra cost , then I ' d put them in , SVM : cost voice recognition simple battery CRF : voice recognition battery STM : extra cost , definitely going voice recognition LCDs , simple battery STM + context : cost , company , advanced integrated circuits , going voice recognition , simple battery , advanced chip , curved case rubber Table 3 : Sample system outputs by different methods are in the third cell ( methods ' names are in bold ).
First cell contains three DRDAs supporting the decision in the second cell and three adjacent DAs of them .
ably to the supervised methods in F scores , and also get the best ROUGE - 1 recalls .
6 . 3 Sample System Summaries To better exemplify the summaries generated by different systems , sample output for each method is shown in Table 3 .
We see from the table that utterance - level extractive summaries ( Longest DA , Prototype DA , TMM ) make more coherent but still far from concise and compact abstracts .
On the other hand , the supervised methods ( SVM , CRF ) that produce token - level extracts better identify the overall content of the decision abstract .
Unfortunately , they require human annotation in the training phase .
In comparison , the output of fine - grained topic models can cover the most useful information .
7 Conclusion We propose a token - level summarization framework based on topic models and show that modeling topic structure at the utterance - level is better at identifying relevant words and phrases than document - level models .
The role of context is also studied and shown to be able to identify additional summary - worthy words .
Acknowledgments This work was supported in part by National Science Foundation Grants IIS - 0968450 and IIS - 1111176 , and by a gift from Google .
