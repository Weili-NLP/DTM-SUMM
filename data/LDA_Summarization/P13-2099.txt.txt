Evolutionary Hierarchical Dirichlet Process for Timeline Summarization Timeline summarization aims at generating concise summaries and giving readers a faster and better access to understand the evolution of news .
It is a new challenge which combines salience ranking problem with novelty detection .
Previous researches in this field seldom explore the evolutionary pattern of topics such as birth , splitting , merging , developing and death .
In this paper , we develop a novel model called Evolutionary Hierarchical Dirichlet Process ( EHDP ) to capture the topic evolution pattern in timeline summarization .
In EHDP , time varying information is formulated as a series of HDPs by considering time - dependent information .
Experiments on 6 different datasets which contain 3156 documents demonstrates the good performance of our system with regard to ROUGE scores .
1 Introduction Faced with thousands of news articles , people usually try to ask the general aspects such as the beginning , the evolutionary pattern and the end .
General search engines simply return the top ranking articles according to query relevance and fail to trace how a specific event goes .
Timeline summarization , which aims at generating a series of concise summaries for news collection published at different epochs can give readers a faster and better access to understand the evolution of news .
The key of timeline summarization is how to select sentences which can tell readers the evolutionary pattern of topics in the event .
It is very common that the themes of a corpus evolve over time , and topics of adjacent epochs usually exhibit strong correlations .
Thus , it is important to model topics across different documents and over different time periods to detect how the events evolve .
The task of timelime summarization is firstly proposed by Allan et al .
( 2001 ) by extracting clusters of noun phases and name entities .
( 2004 ) built a similar system in unit of sentences with interest and burstiness .
However , these methods seldom explored the evolutionary characteristics of news .
Recently , Yan et al .
( 2011 ) extended the graph based sentence ranking algorithm used in traditional multi - document summarization ( MDS ) to timeline generation by projecting sentences from different time into one plane .
They further explored the timeline task from the optimization of a function considering the combination of different respects such as relevance , coverage , coherence and diversity ( Yan et al ., 2011b ).
However , their approaches just treat timeline generation as a sentence ranking or optimization problem and seldom explore the topic information lied in the corpus .
Recently , topic models have been widely used for capturing the dynamics of topics via time .
Many dynamic approaches based on LDA model ( Blei et al ., 2003 ) or Hierarchical Dirichelt Pro - cesses ( HDP ) ( Teh et al ., 2006 ) have been proposed to discover the evolving patterns in the corpus as well as the snapshot clusters at each time epoch ( Blei and Lafferty , 2006 ; Chakrabarti et al ., 2006 ; Wang and McCallum , 2007 ; Caron et al ., 2007 ; Ren et al ., 2008 ; Ahmed and Xing , 2008 ; Zhang et al ., 2010 ).
In this paper , we propose EHDP : a evolutionary hierarchical Dirichlet process ( HDP ) model for timeline summarization .
In EHDP , each HDP is built for multiple corpora at each time epoch , and the time dependencies are incorporated into epochs under the Markovian assumptions .
Topic popularity and topic - word distribution can be inferred from a Chinese Restaurant Process ( CRP ).
Sentences are selected into timelines by considering different aspects such as topic relevance , coverage and coherence .
We built the evaluation systerns which contain 6 real datasets and performance of different models is evaluated according to the ROUGE metrics .
Experimental results demonstrate the effectiveness of our model .
2 EHDP for Timeline Summarization 2 . 1 Problem Formulation Given a general query Q = { wqi } i = Qn , we firstly obtain a set of query related documents .
We no - tate different corpus as C = { C *}*= T according to their published time where C * = { Du }^ denotes the document collection published at epoch t . Document D * is formulated as a collection of sentences { sj } j = N4i .
Each sentence is presented with a series of words s l = N .
and as - sociated with a topic Oj .
V denotes the vocabulary size .
The output of the algorithm is a series of timelines summarization I = { I *}*= T where Our EHDP model is illustrated in Figure 2 .
Specifically , each corpus C is modeled as a HDP .
These HDP shares an identical base measure Go , which serves as an overall bookkeeping of overall measures .
We use GO to denote the base measure at each epoch and draw the local measure Gi for each document at time t from Go .
In EHDP , each sentence is assigned to an aspect Oj with the consideration of words within current sentence .
To consider time dependency information in EHDP , we link all time specific base measures GO with a temporal Dirichlet mixture model as follows : where F ( v , 6 ) = exp (— ö / v ) denotes the exponential kernel function that controls the influence of neighboring corpus .
K denotes the normalization factor where K = 1 + £ s = 0 F ( v , 6 ).
A is the time width and A is the decay factor .
In Chinese Restaurant Process ( CRP ), each document is referred to a restaurant and sentences are compared to customers .
Customers in the restaurant sit around different tables and each table b \ n is associated with a dish ( topic ) \ I >* n according to the dish menu .
Let m * k denote the number of tables enjoying dish k in all restaurants at epoch t , for each epoch t e [ 1 , T ] 1 . draw global measure 2 . for each document D 4 at epoch t , 2 . 2 for each sentence sj in Ddraw aspect 0j ~ G sj draw w ~ f ( w )\ 9 \.
Figure 1 : Generation process for EHDP another parameter M * k to incorporate time dependency into EHDP .
Let n * b denote the number of sentences sitting around table b , in document i at epoch t . In CRP for EHDP , when a new customer sitj comes in , he can sit on the existing table with probability nib /( n *— sharing the dish ( topic ) served at that table or picking a new table with probability 7 /( ni — 1 + 7 ).
The customer has to select a dish from the global dish menu if he chooses a new table .
A dish that has already been shared in the global menu would be chosen with probability Mk /(£ k Mk + a ) and a new dish with probability «/(£ k Mk + a ).
ij lOil , Oij " l , We can see that EHDP degenerates into a series of independent HDPs when A = 0 and one global HDP when A = T and v = 00 , as discussed in Amred and Xings work ( 2008 ).
2 . 3 Sentence Selection Strategy The task of timeline summarization aims to produce a summary for each time and the generated summary should meet criteria such as relevance , coverage and coherence ( Li et al ., 2009 ).
To care for these three criteria , we propose a topic scoring algorithm based on Kullback - Leibler ( KL ) divergence .
We introduce the decreasing logistic function Z ( x ) = 1 /( 1 + ex ) to map the distance into interval ( 0 , 1 ).
Figure 2 : Graphical model of EHDP .
Relevance : the summary should be related with the proposed query Q .
Coverage : the summary should highly generalize important topics mentioned in document collection at epoch t . Coherence : News evolves over time and a good component summary is coherent with neighboring corpus so that a timeline tracks the gradual evolution trajectory for multiple correlative news .
Let Score ( I *) denote the score of the summary and it is calculated in Equ .
Sentences with higher score are selected into timeline .
To avoid aspect redundancy , MMR strategy ( Goldstein et al ., 1999 ) is adopted in the process of sentence selection .
3 Experiments 3 . 1 Experiments set - up We downloaded 3156 news articles from selected sources such as BBC , New York Times and CNN with various time spans and built the evaluation systems which contains 6 real datasets .
The news belongs to different categories of Rule of Interpretation ( ROI ) ( Kumaran and Allan , 2004 ).
Detailed statistics are shown in Table 1 .
Dataset 2 ( Deep - water Horizon oil spill ), 3 ( Haiti Earthquake ) and 5 ( Hurricane Sandy ) are used as training data and the rest are used as test data .
Summary at each epoch is truncated to the same length of 50 words .
Summaries produced by baseline systems and ours are automatically evaluated through ROUGE evaluation metrics ( Lin and Hovy , 2003 ).
For the space limit , we only report three ROUGE ROUGE - 2 - F and ROUGE - W - F score .
Reference timeline in ROUGE evaluation is manually generated by using Amazon Mechanical Turk .
Workers were asked to generate reference timeline for news at each epoch in less than 50 words and we collect 790 timelines in total .
3 . 2 Parameter Tuning To tune the parameters A ( i = 1 , 2 , 3 ) and v in our system , we adopt a gradient search strategy .
We firstly fix Ai to 1 / 3 .
Then we perform experiments on with setting different values of v /# epoch in the range from 0 . 02 to 0 . 2 at the interval of 0 . 02 .
We find that the Rouge score reaches its peak at round 0 . 1 and drops afterwards in the experiments .
Next , we set the value of v is set to 0 . 1 • # epoch and gradually change the value of Ai from 0 to 1 with interval of 0 . 05 , with simultaneously fixing A2 and A3 to the same value of ( 1 — Ai )/ 2 .
The performance gets better as Ai increases from 0 to 0 . 25 and then declines .
Then we set the value of Ai to 0 . 25 and change the value of A2 from 0 to 0 . 75 with interval of 0 . 05 .
And the value of A2 is set to 0 . 4 , and A3 is set to 0 . 35 correspondingly .
3 . 3 Comparison with other topic models In this subsection , we compare our model with 4 topic model baselines on the test data .
Stand - HDP ( 1 ): A topic approach that models different time epochs as a series of independent HDPs without considering time dependency .
Stand - HDP ( 2 ): http :// mturk . com Table 1 : New sources of datasets Table 2 : Detailed information for datasets A global HDP which models the whole time span as a restaurant .
The third baseline , Dynamic - LDA is based on Blei and Laffery ( 2007 )' s work and Stan - LDA is based on standard LDA model .
In LDA based models , aspect number is predefined as 80 .
Experimental results of different models are shown in Table 2 .
As we can see , EHDP achieves better results than the two standard HDP baselines where time information is not adequately considered .
We also find an interesting result that Stan - HDP performs better than Stan - LDA .
This is partly because new aspects can be automatically detected in HDP .
As we know , how to determine topic number in the LDA - based models is still an open problem .
3 . 4 Comparison with other baselines We implement several baselines used in traditional summarization or timeline summarization for comparison .
( 1 ) Centroid applies the MEAD algorithm ( Radev et al ., 2004 ) according to the features including centroid value , position and first - sentence overlap .
( 2 ) Manifold is a graph based unsupervised method for summarization , and the score of each sentence is got from the propagation through the graph ( Wan et al ., 2007 ).
( 3 ) ETS is the timeline summarization approach developed by Yan et al ., ( 2011a ), which is a graph based approach with optimized global and local biased summarization .
( 4 ) Chieu is the timeline system provided by ( Chieu and Lee , 2004 ) utilizing interest and bursty ranking but neglecting trans - temporal news evolution .
As we can see from Table 3 , Centroid and Manifold get the worst results .
This is probably because methods in multi - document summarization only care about sentence selection and neglect the novelty detection task .
We can also see that EHDP under our proposed framework outputs existing timeline summarization approaches ETS and chieu .
Our approach outputs Yan et al .,( 2011a ) s model by 6 . 9 % and 9 . 3 % respectively with regard to the average score of ROUGE - 2 - F and ROUGE - W - F .
In our experiments , the aspect number is set as 50 , 80 , 100 and 120 respectively and we select the best performed result with the aspect number as 80 4 Conclusion In this paper we present an evolutionary HDP model for timeline summarization .
Our EHDP extends original HDP by incorporating time dependencies and background information .
We also develop an effective sentence selection strategy for candidate in the summaries .
Experimental results on real multi - time news demonstrate the effectiveness of our topic model .
S1 : The first debate between President Obama and Mitt Romney , so long anticipated , quickly sunk into an unenlightening recitation of tired talking points and mendacity .
Mr . Romney wants to restore the Bush - era tax cut that expires at the end of this year and largely benefits the wealthy S1 : The vice presidential debate took place on Thursday , October 11 at Kentucky ' sCentre College , and was moderated by Martha Raddatz .
S2 : The first and only debate between Vice President Joe Biden and Congressman Paul Ryan focused on domestic and foreign policy .
The domestic policy segments included questions on health care , abortion Oct . 16 , 2012 S1 .
President Obama fights back in his second debate with Mitt Romney , banishing some of the doubts he raised in their first showdown .
S2 : The second debate dealt primarily with domestic affairs and include some segues into foreign policy .
including taxes , unemployment , job creation , the national debt , energy and women ' s rights , both legal and Table 5 : Selected timeline summarization generated by EHDP for American Presidential Election 5 Acknowledgement Program ( No . 2012AA011101 ) and National Social Science Foundation ( No . 12ZD227 ).
Table 3 : Comparison with topic models Table 4 : Comparison with other baselines
